{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SD - SR "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following notebook allows to replicate the simulation as describe in Alamia et al. (2019). CNN and a Siamese networks are compared when performing identity (SD) and Spatial Relationship (SR) tasks. See Alamia et al. (2019) for further details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After having imported a bunch of packages, we load the data from a previously genereated Matlab file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import time\n",
    "import csv\n",
    "from keras.layers.core import Dense, Activation, Dropout, Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers import MaxPooling2D, Conv2D, ZeroPadding2D, Activation, Input, concatenate, Add, Multiply\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras import regularizers, optimizers\n",
    "from keras.utils import np_utils\n",
    "np.random.seed(1234)\n",
    "\n",
    "import tensorflow as tf \n",
    "import keras\n",
    "from keras.layers.merge import _Merge\n",
    "\n",
    "import scipy.io as sio\n",
    "from scipy import stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getImagesNlabelsSiam() :\n",
    "\n",
    "    infile = sio.loadmat('siamese1000val.mat')\n",
    "    \n",
    "    allTrialsTr = infile.get('allTrialsTr')\n",
    "    SRconditionsTr=infile.get('SRconditionsTr')\n",
    "    SDconditionsTr=infile.get('SDconditionsTr')\n",
    "    \n",
    "    allTrialsVal = infile.get('allTrialsVal')\n",
    "    SRconditionsVal=infile.get('SRconditionsVal')\n",
    "    SDconditionsVal=infile.get('SDconditionsVal')\n",
    "    \n",
    "    allTrialsTe = infile.get('allTrialsTe')\n",
    "    SRconditionsTe=infile.get('SRconditionsTe')\n",
    "    SDconditionsTe=infile.get('SDconditionsTe')\n",
    "\n",
    "    #shuffling training\n",
    "    perm = np.arange(allTrialsTr.shape[3])  \n",
    "    np.random.shuffle(perm)  \n",
    "    allTrialsTrPerm = allTrialsTr[:,:,:,perm] \n",
    "    SRconditionsTrPerm = SRconditionsTr[:,perm] \n",
    "    SDconditionsTrPerm = SDconditionsTr[:,perm] \n",
    "   \n",
    "    #providing it with the right dimensions  training\n",
    "    allTrialsTrRearranged=np.moveaxis(allTrialsTrPerm,-1,0)\n",
    "    SDconditionsTrRearranged=np.moveaxis(SDconditionsTrPerm,-1,0)\n",
    "    SRconditionsTrRearranged=np.moveaxis(SRconditionsTrPerm,-1,0)\n",
    "    allTrialsTrRearranged2 = np.expand_dims(allTrialsTrRearranged,axis=-1)\n",
    "    allTrialsTrRearranged2 = allTrialsTrRearranged\n",
    "    \n",
    "    \n",
    "    #shuffling validation\n",
    "    perm = np.arange(allTrialsVal.shape[3])  \n",
    "    np.random.shuffle(perm)  \n",
    "    allTrialsValPerm = allTrialsVal[:,:,:,perm] \n",
    "    SRconditionsValPerm = SRconditionsVal[:,perm] \n",
    "    SDconditionsValPerm = SDconditionsVal[:,perm] \n",
    "   \n",
    "    #providing it with the right dimensions validation\n",
    "    allTrialsValRearranged=np.moveaxis(allTrialsValPerm,-1,0)\n",
    "    SDconditionsValRearranged=np.moveaxis(SDconditionsValPerm,-1,0)\n",
    "    SRconditionsValRearranged=np.moveaxis(SRconditionsValPerm,-1,0)\n",
    "    allTrialsValRearranged2 = np.expand_dims(allTrialsValRearranged,axis=-1)\n",
    "    allTrialsValRearranged2 = allTrialsValRearranged\n",
    "    \n",
    "    \n",
    "    #shuffling testing\n",
    "    perm = np.arange(allTrialsTe.shape[3])  \n",
    "    np.random.shuffle(perm)  \n",
    "    allTrialsTePerm = allTrialsTe[:,:,:,perm] \n",
    "    SRconditionsTePerm = SRconditionsTe[:,perm] \n",
    "    SDconditionsTePerm = SDconditionsTe[:,perm] \n",
    "   \n",
    "    #providing it with the right dimensions  testing\n",
    "    allTrialsTeRearranged=np.moveaxis(allTrialsTePerm,-1,0)\n",
    "    SDconditionsTeRearranged=np.moveaxis(SDconditionsTePerm,-1,0)\n",
    "    SRconditionsTeRearranged=np.moveaxis(SRconditionsTePerm,-1,0)\n",
    "    allTrialsTeRearranged2 = np.expand_dims(allTrialsTeRearranged,axis=-1)\n",
    "    allTrialsTeRearranged2 = allTrialsTeRearranged\n",
    "    \n",
    "    return {'imagesTr':allTrialsTrRearranged2,'SRlabelsTr':SRconditionsTrRearranged,'SDlabelsTr':SDconditionsTrRearranged,'imagesVal':allTrialsValRearranged2,'SRlabelsVal':SRconditionsValRearranged,'SDlabelsVal':SDconditionsValRearranged,'imagesTe':allTrialsTeRearranged2,'SRlabelsTe':SRconditionsTeRearranged,'SDlabelsTe':SDconditionsTeRearranged}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getImagesNlabels() :\n",
    "\n",
    "    #infile = sio.loadmat('artVisDataset.mat')\n",
    "    infile = sio.loadmat('cnn1000val.mat')\n",
    "\n",
    "    allTrialsTr = infile.get('allTrialsTr')\n",
    "    SRconditionsTr=infile.get('SRconditionsTr')\n",
    "    SDconditionsTr=infile.get('SDconditionsTr')\n",
    "    \n",
    "    allTrialsVal = infile.get('allTrialsVal')\n",
    "    SRconditionsVal=infile.get('SRconditionsVal')\n",
    "    SDconditionsVal=infile.get('SDconditionsVal')\n",
    "    \n",
    "    allTrialsTe = infile.get('allTrialsTe')\n",
    "    SRconditionsTe=infile.get('SRconditionsTe')\n",
    "    SDconditionsTe=infile.get('SDconditionsTe')\n",
    "    \n",
    "\n",
    "    #shuffling training\n",
    "    perm = np.arange(allTrialsTr.shape[2])  \n",
    "    np.random.shuffle(perm)  \n",
    "    allTrialsTrPerm = allTrialsTr[:,:,perm] \n",
    "    SRconditionsTrPerm = SRconditionsTr[:,perm] \n",
    "    SDconditionsTrPerm = SDconditionsTr[:,perm] \n",
    "   \n",
    "    #providing it with the right dimensions  training\n",
    "    allTrialsTrRearranged=np.moveaxis(allTrialsTrPerm,-1,0)\n",
    "    SDconditionsTrRearranged=np.moveaxis(SDconditionsTrPerm,-1,0)\n",
    "    SRconditionsTrRearranged=np.moveaxis(SRconditionsTrPerm,-1,0)\n",
    "    allTrialsTrRearranged2 = np.expand_dims(allTrialsTrRearranged,axis=-1)\n",
    "    \n",
    "        \n",
    "    #shuffling validation\n",
    "    perm = np.arange(allTrialsVal.shape[2])  \n",
    "    np.random.shuffle(perm)  \n",
    "    allTrialsValPerm = allTrialsVal[:,:,perm] \n",
    "    SRconditionsValPerm = SRconditionsVal[:,perm] \n",
    "    SDconditionsValPerm = SDconditionsVal[:,perm] \n",
    "   \n",
    "    #providing it with the right dimensions validation\n",
    "    allTrialsValRearranged=np.moveaxis(allTrialsValPerm,-1,0)\n",
    "    SDconditionsValRearranged=np.moveaxis(SDconditionsValPerm,-1,0)\n",
    "    SRconditionsValRearranged=np.moveaxis(SRconditionsValPerm,-1,0)\n",
    "    allTrialsValRearranged2 = np.expand_dims(allTrialsValRearranged,axis=-1)\n",
    "    allTrialsValRearranged2 = allTrialsValRearranged\n",
    "    \n",
    "    \n",
    "    #shuffling testing\n",
    "    perm = np.arange(allTrialsTe.shape[2])  \n",
    "    np.random.shuffle(perm)  \n",
    "    allTrialsTePerm = allTrialsTe[:,:,perm] \n",
    "    SRconditionsTePerm = SRconditionsTe[:,perm] \n",
    "    SDconditionsTePerm = SDconditionsTe[:,perm] \n",
    "   \n",
    "    #providing it with the right dimensions  testing\n",
    "    allTrialsTeRearranged=np.moveaxis(allTrialsTePerm,-1,0)\n",
    "    SDconditionsTeRearranged=np.moveaxis(SDconditionsTePerm,-1,0)\n",
    "    SRconditionsTeRearranged=np.moveaxis(SRconditionsTePerm,-1,0)\n",
    "    allTrialsTeRearranged2 = np.expand_dims(allTrialsTeRearranged,axis=-1)\n",
    "    \n",
    "    return {'imagesTr':allTrialsTrRearranged2,'SRlabelsTr':SRconditionsTrRearranged,'SDlabelsTr':SDconditionsTrRearranged,'imagesTe':allTrialsTeRearranged2,'SRlabelsTe':SRconditionsTeRearranged,'SDlabelsTe':SDconditionsTeRearranged}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next two cells we define the Siamese Network and the convolutional one. Note that in the Siamese network we redefine the class Substract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Subtract(_Merge):\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(Subtract, self).build(input_shape)\n",
    "        if len(input_shape) != 2:\n",
    "            raise ValueError('A `Subtract` layer should be called '\n",
    "                             'on exactly 2 inputs')\n",
    "\n",
    "    def _merge_function(self, inputs):\n",
    "        if len(inputs) != 2:\n",
    "            raise ValueError('A `Subtract` layer should be called '\n",
    "                             'on exactly 2 inputs')\n",
    "        return inputs[0] - inputs[1]\n",
    "\n",
    "\n",
    "def get_siamese_model(images):\n",
    "\n",
    "    # Define the tensors for the two input images\n",
    "#     left_input = Input(images[:,:,:,0].shape)\n",
    "#     right_input = Input(images[:,:,:,1].shape)\n",
    "#     left_input = np.expand_dims(left_input,axis=-1)\n",
    "#     right_input = np.expand_dims(right_input,axis=-1)\n",
    "#     left_input = Input(left_input.shape)\n",
    "#     right_input = Input(right_input.shape)\n",
    "    \n",
    "    input_shape = (images.shape[1], images.shape[2], 1)\n",
    "    left_input = Input(input_shape)\n",
    "    right_input = Input(input_shape)\n",
    "    \n",
    "    \n",
    "    # Convolutional Neural Network\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(4, (2, 2), strides=1, input_shape=(images.shape[1], images.shape[2], 1), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=1))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Conv2D(4, (2, 2), strides=1, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=1))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Conv2D(4, (2, 2), strides=1, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=1))   \n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Conv2D(4, (2, 2), strides=1, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=1))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Conv2D(4, (2, 2), strides=1, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=1))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Conv2D(4, (2, 2), strides=1, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=1))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    # Generate the encodings (feature vectors) for the two images\n",
    "    encoded_l = model(left_input)\n",
    "    encoded_r = model(right_input)\n",
    "    \n",
    "    combineFeatures2 = Subtract()([encoded_l, encoded_r])\n",
    "    \n",
    "    # Add a dense layer with a sigmoid unit to generate the similarity score\n",
    "    prediction1 = Dense(128,activation='relu')(combineFeatures2)\n",
    "    prediction1do = Dropout(.3)(prediction1)\n",
    "    prediction2 = Dense(128,activation='relu')(prediction1)\n",
    "    prediction2do = Dropout(.3)(prediction2)\n",
    "    prediction = Dense(1,activation='sigmoid')(prediction2do)\n",
    "    \n",
    "    # Connect the inputs with the outputs\n",
    "    siamese_net = Model(inputs=[left_input,right_input],outputs=prediction)\n",
    "    \n",
    "    siamese_net.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=optimizers.Adam(lr=0.0001))\n",
    "    \n",
    "    # return the model\n",
    "    return siamese_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def buildingTheNetwork(images) :\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(4, (2, 2), strides=1, input_shape=(images.shape[1], images.shape[2], 1), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=1))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(4, (2, 2), strides=1, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=1))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(4, (2, 2), strides=1, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=1))   \n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(4, (2, 2), strides=1, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=1))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(4, (2, 2), strides=1, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=1))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(4, (2, 2), strides=1, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=1))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(4, (2, 2), strides=1, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=1))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=optimizers.Adam(lr=0.0001),)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we finally run the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 49, 49, 4)         20        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 48, 48, 4)         0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 48, 48, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 47, 47, 4)         68        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 46, 46, 4)         0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 46, 46, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 45, 45, 4)         68        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 44, 44, 4)         0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 44, 44, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 43, 43, 4)         68        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 42, 42, 4)         0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 42, 42, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 41, 41, 4)         68        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 40, 40, 4)         0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 40, 40, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 39, 39, 4)         68        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 38, 38, 4)         0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 38, 38, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 37, 37, 4)         68        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 36, 36, 4)         0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 36, 36, 4)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 5184)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               663680    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 129       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 680,749.0\n",
      "Trainable params: 680,749.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 49, 49, 4)         20        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 48, 48, 4)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 48, 48, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 47, 47, 4)         68        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 46, 46, 4)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 46, 46, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 45, 45, 4)         68        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 44, 44, 4)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 44, 44, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 43, 43, 4)         68        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 42, 42, 4)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 42, 42, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 41, 41, 4)         68        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 40, 40, 4)         0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 40, 40, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 39, 39, 4)         68        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 38, 38, 4)         0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 38, 38, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 37, 37, 4)         68        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 36, 36, 4)         0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 36, 36, 4)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 5184)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               663680    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 129       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 680,749.0\n",
      "Trainable params: 680,749.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 50, 50, 1)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_2 (InputLayer)             (None, 50, 50, 1)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "sequential_3 (Sequential)        (None, 5776)          360                                          \n",
      "____________________________________________________________________________________________________\n",
      "subtract_1 (Subtract)            (None, 5776)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_7 (Dense)                  (None, 128)           739456                                       \n",
      "____________________________________________________________________________________________________\n",
      "dense_8 (Dense)                  (None, 128)           16512                                        \n",
      "____________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)             (None, 128)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_9 (Dense)                  (None, 1)             129                                          \n",
      "====================================================================================================\n",
      "Total params: 756,457.0\n",
      "Trainable params: 756,457.0\n",
      "Non-trainable params: 0.0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "data=getImagesNlabels() \n",
    "imagesTr=data['imagesTr']\n",
    "SRlabelsTr=data['SRlabelsTr']\n",
    "SDlabelsTr=data['SDlabelsTr']\n",
    "\n",
    "imagesTe=data['imagesTe']\n",
    "SRlabelsTe=data['SRlabelsTe']\n",
    "SDlabelsTe=data['SDlabelsTe']\n",
    "\n",
    "\n",
    "dataSiam=getImagesNlabelsSiam() \n",
    "imagesTrSiam=dataSiam['imagesTr']\n",
    "SRlabelsTrSiam=dataSiam['SRlabelsTr']\n",
    "SDlabelsTrSiam=dataSiam['SDlabelsTr']\n",
    "\n",
    "imagesValSiam=dataSiam['imagesVal']\n",
    "SRlabelsValSiam=dataSiam['SRlabelsVal']\n",
    "SDlabelsValSiam=dataSiam['SDlabelsVal']\n",
    "\n",
    "imagesTeSiam=dataSiam['imagesTe']\n",
    "SRlabelsTeSiam=dataSiam['SRlabelsTe']\n",
    "SDlabelsTeSiam=dataSiam['SDlabelsTe']\n",
    "\n",
    "\n",
    "imagesTrNewL=imagesTrSiam[:,:,:,0]\n",
    "imagesTrNewR=imagesTrSiam[:,:,:,1]\n",
    "imagesTrNewL = np.expand_dims(imagesTrNewL,axis=-1)\n",
    "imagesTrNewR = np.expand_dims(imagesTrNewR,axis=-1)\n",
    "\n",
    "imagesValNewL=imagesValSiam[:,:,:,0]\n",
    "imagesValNewR=imagesValSiam[:,:,:,1]\n",
    "imagesValNewL = np.expand_dims(imagesValNewL,axis=-1)\n",
    "imagesValNewR = np.expand_dims(imagesValNewR,axis=-1)\n",
    "\n",
    "imagesTeNewL=imagesTeSiam[:,:,:,0]\n",
    "imagesTeNewR=imagesTeSiam[:,:,:,1]\n",
    "imagesTeNewL = np.expand_dims(imagesTeNewL,axis=-1)\n",
    "imagesTeNewR = np.expand_dims(imagesTeNewR,axis=-1)\n",
    "\n",
    "networkSR=buildingTheNetwork(imagesTr) \n",
    "networkSD=buildingTheNetwork(imagesTr) \n",
    "\n",
    "siamNetSD=get_siamese_model(imagesTrSiam) \n",
    "\n",
    "networkSD.summary()\n",
    "networkSR.summary()\n",
    "siamNetSD.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and finally we fit the models!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1000/1000 [==============================] - 4s - loss: 0.6621 - acc: 0.7290     \n",
      "Epoch 2/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.5489 - acc: 0.9170     \n",
      "Epoch 3/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.3657 - acc: 0.9310     \n",
      "Epoch 4/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.2226 - acc: 0.9410     \n",
      "Epoch 5/70\n",
      "1000/1000 [==============================] - 4s - loss: 0.1491 - acc: 0.9510     \n",
      "Epoch 6/70\n",
      "1000/1000 [==============================] - 4s - loss: 0.1164 - acc: 0.9550     \n",
      "Epoch 7/70\n",
      "1000/1000 [==============================] - 4s - loss: 0.0770 - acc: 0.9780     \n",
      "Epoch 8/70\n",
      "1000/1000 [==============================] - 4s - loss: 0.0589 - acc: 0.9870     \n",
      "Epoch 9/70\n",
      "1000/1000 [==============================] - 4s - loss: 0.0576 - acc: 0.9830     \n",
      "Epoch 10/70\n",
      "1000/1000 [==============================] - 4s - loss: 0.0361 - acc: 0.9940     \n",
      "Epoch 11/70\n",
      "1000/1000 [==============================] - 4s - loss: 0.0252 - acc: 0.9960     \n",
      "Epoch 12/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.0177 - acc: 0.9960     \n",
      "Epoch 13/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.0124 - acc: 0.9990     \n",
      "Epoch 14/70\n",
      "1000/1000 [==============================] - 4s - loss: 0.0130 - acc: 0.9970     \n",
      "Epoch 15/70\n",
      "1000/1000 [==============================] - 4s - loss: 0.0125 - acc: 0.9960     \n",
      "Epoch 16/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.0078 - acc: 1.0000     \n",
      "Epoch 17/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.0045 - acc: 1.0000     \n",
      "Epoch 18/70\n",
      "1000/1000 [==============================] - 4s - loss: 0.0055 - acc: 1.0000     \n",
      "Epoch 19/70\n",
      "1000/1000 [==============================] - 5s - loss: 0.0042 - acc: 1.0000     \n",
      "Epoch 20/70\n",
      "1000/1000 [==============================] - 5s - loss: 0.0032 - acc: 1.0000     \n",
      "Epoch 21/70\n",
      "1000/1000 [==============================] - 5s - loss: 0.0024 - acc: 1.0000     \n",
      "Epoch 22/70\n",
      "1000/1000 [==============================] - 5s - loss: 0.0041 - acc: 0.9990     \n",
      "Epoch 23/70\n",
      "1000/1000 [==============================] - 4s - loss: 0.0020 - acc: 1.0000     \n",
      "Epoch 24/70\n",
      "1000/1000 [==============================] - 4s - loss: 0.0030 - acc: 0.9990     \n",
      "Epoch 25/70\n",
      "1000/1000 [==============================] - 5s - loss: 0.0017 - acc: 1.0000     \n",
      "Epoch 26/70\n",
      "1000/1000 [==============================] - 4s - loss: 0.0015 - acc: 1.0000     \n",
      "Epoch 27/70\n",
      "1000/1000 [==============================] - 4s - loss: 0.0023 - acc: 1.0000     - ETA: 1s - loss: 0.0022 - acc:\n",
      "Epoch 28/70\n",
      "1000/1000 [==============================] - 4s - loss: 0.0014 - acc: 1.0000     \n",
      "Epoch 29/70\n",
      "1000/1000 [==============================] - 4s - loss: 0.0018 - acc: 0.9990     \n",
      "Epoch 30/70\n",
      "1000/1000 [==============================] - 4s - loss: 8.1831e-04 - acc: 1.0000     \n",
      "Epoch 31/70\n",
      "1000/1000 [==============================] - 4s - loss: 0.0013 - acc: 1.0000     \n",
      "Epoch 32/70\n",
      "1000/1000 [==============================] - 4s - loss: 0.0016 - acc: 1.0000     \n",
      "Epoch 33/70\n",
      "1000/1000 [==============================] - 4s - loss: 9.8056e-04 - acc: 1.0000 \n",
      "Epoch 34/70\n",
      "1000/1000 [==============================] - 4s - loss: 0.0011 - acc: 1.0000     \n",
      "Epoch 35/70\n",
      "1000/1000 [==============================] - 4s - loss: 6.7665e-04 - acc: 1.0000     \n",
      "Epoch 36/70\n",
      "1000/1000 [==============================] - 4s - loss: 6.3044e-04 - acc: 1.0000     \n",
      "Epoch 37/70\n",
      "1000/1000 [==============================] - 5s - loss: 4.6144e-04 - acc: 1.0000     \n",
      "Epoch 38/70\n",
      "1000/1000 [==============================] - 4s - loss: 5.0650e-04 - acc: 1.0000     \n",
      "Epoch 39/70\n",
      "1000/1000 [==============================] - 4s - loss: 5.8765e-04 - acc: 1.0000     \n",
      "Epoch 40/70\n",
      "1000/1000 [==============================] - 3s - loss: 5.7216e-04 - acc: 1.0000     \n",
      "Epoch 41/70\n",
      "1000/1000 [==============================] - 3s - loss: 5.4959e-04 - acc: 1.0000     \n",
      "Epoch 42/70\n",
      "1000/1000 [==============================] - 3s - loss: 4.6017e-04 - acc: 1.0000     \n",
      "Epoch 43/70\n",
      "1000/1000 [==============================] - 3s - loss: 5.0061e-04 - acc: 1.0000     \n",
      "Epoch 44/70\n",
      "1000/1000 [==============================] - 3s - loss: 5.3431e-04 - acc: 1.0000     \n",
      "Epoch 45/70\n",
      "1000/1000 [==============================] - 3s - loss: 3.1951e-04 - acc: 1.0000     \n",
      "Epoch 46/70\n",
      "1000/1000 [==============================] - 3s - loss: 4.0625e-04 - acc: 1.0000     \n",
      "Epoch 47/70\n",
      "1000/1000 [==============================] - 3s - loss: 3.2646e-04 - acc: 1.0000     \n",
      "Epoch 48/70\n",
      "1000/1000 [==============================] - 4s - loss: 2.3670e-04 - acc: 1.0000     \n",
      "Epoch 49/70\n",
      "1000/1000 [==============================] - 3s - loss: 2.7839e-04 - acc: 1.0000     \n",
      "Epoch 50/70\n",
      "1000/1000 [==============================] - 3s - loss: 2.8200e-04 - acc: 1.0000     \n",
      "Epoch 51/70\n",
      "1000/1000 [==============================] - 4s - loss: 5.3801e-04 - acc: 1.0000     \n",
      "Epoch 52/70\n",
      "1000/1000 [==============================] - 3s - loss: 2.5055e-04 - acc: 1.0000     \n",
      "Epoch 53/70\n",
      "1000/1000 [==============================] - 3s - loss: 3.2282e-04 - acc: 1.0000     \n",
      "Epoch 54/70\n",
      "1000/1000 [==============================] - 3s - loss: 5.7692e-04 - acc: 1.0000     \n",
      "Epoch 55/70\n",
      "1000/1000 [==============================] - 4s - loss: 1.9331e-04 - acc: 1.0000     \n",
      "Epoch 56/70\n",
      "1000/1000 [==============================] - 4s - loss: 3.7403e-04 - acc: 1.0000     \n",
      "Epoch 57/70\n",
      "1000/1000 [==============================] - 3s - loss: 6.2194e-04 - acc: 1.0000     \n",
      "Epoch 58/70\n",
      "1000/1000 [==============================] - 3s - loss: 2.2222e-04 - acc: 1.0000     \n",
      "Epoch 59/70\n",
      "1000/1000 [==============================] - 3s - loss: 4.6012e-04 - acc: 1.0000     \n",
      "Epoch 60/70\n",
      "1000/1000 [==============================] - 4s - loss: 1.2533e-04 - acc: 1.0000     \n",
      "Epoch 61/70\n",
      "1000/1000 [==============================] - 4s - loss: 5.2872e-04 - acc: 1.0000     \n",
      "Epoch 62/70\n",
      "1000/1000 [==============================] - 3s - loss: 1.2581e-04 - acc: 1.0000     \n",
      "Epoch 63/70\n",
      "1000/1000 [==============================] - 3s - loss: 1.2684e-04 - acc: 1.0000     \n",
      "Epoch 64/70\n",
      "1000/1000 [==============================] - 3s - loss: 9.0096e-05 - acc: 1.0000     \n",
      "Epoch 65/70\n",
      "1000/1000 [==============================] - 3s - loss: 1.0001e-04 - acc: 1.0000     \n",
      "Epoch 66/70\n",
      "1000/1000 [==============================] - 3s - loss: 9.4699e-05 - acc: 1.0000     \n",
      "Epoch 67/70\n",
      "1000/1000 [==============================] - 3s - loss: 9.1780e-05 - acc: 1.0000     \n",
      "Epoch 68/70\n",
      "1000/1000 [==============================] - 3s - loss: 1.2480e-04 - acc: 1.0000     \n",
      "Epoch 69/70\n",
      "1000/1000 [==============================] - 4s - loss: 1.2244e-04 - acc: 1.0000     \n",
      "Epoch 70/70\n",
      "1000/1000 [==============================] - 3s - loss: 7.4581e-05 - acc: 1.0000     \n",
      "Epoch 1/70\n",
      "1000/1000 [==============================] - 4s - loss: 0.6926 - acc: 0.5200     \n",
      "Epoch 2/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.6879 - acc: 0.5630     \n",
      "Epoch 3/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.6822 - acc: 0.5850     \n",
      "Epoch 4/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.6776 - acc: 0.6010     \n",
      "Epoch 5/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.6726 - acc: 0.5950     \n",
      "Epoch 6/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.6620 - acc: 0.6300     \n",
      "Epoch 7/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.6538 - acc: 0.6410     \n",
      "Epoch 8/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.6419 - acc: 0.6590     \n",
      "Epoch 9/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.6308 - acc: 0.6690     \n",
      "Epoch 10/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.6157 - acc: 0.7080     \n",
      "Epoch 11/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.5913 - acc: 0.7230     \n",
      "Epoch 12/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.5715 - acc: 0.7200     \n",
      "Epoch 13/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.5404 - acc: 0.7590     \n",
      "Epoch 14/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.5049 - acc: 0.7710     \n",
      "Epoch 15/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.4801 - acc: 0.7750     \n",
      "Epoch 16/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 3s - loss: 0.4467 - acc: 0.7950     \n",
      "Epoch 17/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.4033 - acc: 0.8330     \n",
      "Epoch 18/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.3948 - acc: 0.8250     \n",
      "Epoch 19/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.3708 - acc: 0.8450     \n",
      "Epoch 20/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.3434 - acc: 0.8540     \n",
      "Epoch 21/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.2931 - acc: 0.8890     \n",
      "Epoch 22/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.2830 - acc: 0.8740     \n",
      "Epoch 23/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.2431 - acc: 0.9080     \n",
      "Epoch 24/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.2460 - acc: 0.8950     \n",
      "Epoch 25/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.1991 - acc: 0.9180     \n",
      "Epoch 26/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.2194 - acc: 0.9100     \n",
      "Epoch 27/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.1909 - acc: 0.9270     \n",
      "Epoch 28/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.1899 - acc: 0.9270     \n",
      "Epoch 29/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.1763 - acc: 0.9350     \n",
      "Epoch 30/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.1554 - acc: 0.9430     \n",
      "Epoch 31/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.1478 - acc: 0.9420     \n",
      "Epoch 32/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.1507 - acc: 0.9380     \n",
      "Epoch 33/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.1386 - acc: 0.9450     \n",
      "Epoch 34/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.1153 - acc: 0.9620     \n",
      "Epoch 35/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.1134 - acc: 0.9660     \n",
      "Epoch 36/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.1193 - acc: 0.9570     \n",
      "Epoch 37/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.0989 - acc: 0.9680     \n",
      "Epoch 38/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.1012 - acc: 0.9640     \n",
      "Epoch 39/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.0945 - acc: 0.9700     \n",
      "Epoch 40/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.0788 - acc: 0.9720     \n",
      "Epoch 41/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.0962 - acc: 0.9600     \n",
      "Epoch 42/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.0912 - acc: 0.9680     \n",
      "Epoch 43/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.0914 - acc: 0.9720     \n",
      "Epoch 44/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.0939 - acc: 0.9690     \n",
      "Epoch 45/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.0686 - acc: 0.9740     \n",
      "Epoch 46/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.0648 - acc: 0.9800     \n",
      "Epoch 47/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.0758 - acc: 0.9760     \n",
      "Epoch 48/70\n",
      "1000/1000 [==============================] - 4s - loss: 0.0724 - acc: 0.9760     \n",
      "Epoch 49/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.0584 - acc: 0.9820     \n",
      "Epoch 50/70\n",
      "1000/1000 [==============================] - 4s - loss: 0.0600 - acc: 0.9740     \n",
      "Epoch 51/70\n",
      "1000/1000 [==============================] - 4s - loss: 0.0472 - acc: 0.9840     \n",
      "Epoch 52/70\n",
      "1000/1000 [==============================] - 4s - loss: 0.0644 - acc: 0.9790     - ETA: 0s - loss: 0.0665 - acc: 0.97\n",
      "Epoch 53/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.0642 - acc: 0.9780     \n",
      "Epoch 54/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.0563 - acc: 0.9750     \n",
      "Epoch 55/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.0516 - acc: 0.9830     \n",
      "Epoch 56/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.0505 - acc: 0.9790     \n",
      "Epoch 57/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.0446 - acc: 0.9860     \n",
      "Epoch 58/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.0386 - acc: 0.9920     \n",
      "Epoch 59/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.0402 - acc: 0.9870     \n",
      "Epoch 60/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.0278 - acc: 0.9940     \n",
      "Epoch 61/70\n",
      "1000/1000 [==============================] - 4s - loss: 0.0383 - acc: 0.9870     \n",
      "Epoch 62/70\n",
      "1000/1000 [==============================] - 4s - loss: 0.0443 - acc: 0.9830     \n",
      "Epoch 63/70\n",
      "1000/1000 [==============================] - 4s - loss: 0.0349 - acc: 0.9880     \n",
      "Epoch 64/70\n",
      "1000/1000 [==============================] - 4s - loss: 0.0371 - acc: 0.9840     \n",
      "Epoch 65/70\n",
      "1000/1000 [==============================] - 4s - loss: 0.0322 - acc: 0.9910     \n",
      "Epoch 66/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.0394 - acc: 0.9840     \n",
      "Epoch 67/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.0300 - acc: 0.9900     \n",
      "Epoch 68/70\n",
      "1000/1000 [==============================] - 4s - loss: 0.0371 - acc: 0.9850     \n",
      "Epoch 69/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.0382 - acc: 0.9840     \n",
      "Epoch 70/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.0339 - acc: 0.9860     \n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/70\n",
      "1000/1000 [==============================] - 9s - loss: 0.6934 - acc: 0.5060 - val_loss: 0.6930 - val_acc: 0.4950\n",
      "Epoch 2/70\n",
      "1000/1000 [==============================] - 8s - loss: 0.6884 - acc: 0.5490 - val_loss: 0.6929 - val_acc: 0.5120\n",
      "Epoch 3/70\n",
      "1000/1000 [==============================] - 8s - loss: 0.6837 - acc: 0.5620 - val_loss: 0.6926 - val_acc: 0.5320\n",
      "Epoch 4/70\n",
      "1000/1000 [==============================] - 8s - loss: 0.6808 - acc: 0.5730 - val_loss: 0.6923 - val_acc: 0.5430\n",
      "Epoch 5/70\n",
      "1000/1000 [==============================] - 7s - loss: 0.6724 - acc: 0.5970 - val_loss: 0.6920 - val_acc: 0.5480\n",
      "Epoch 6/70\n",
      "1000/1000 [==============================] - 8s - loss: 0.6646 - acc: 0.6200 - val_loss: 0.6915 - val_acc: 0.5210\n",
      "Epoch 7/70\n",
      "1000/1000 [==============================] - 8s - loss: 0.6661 - acc: 0.5850 - val_loss: 0.6913 - val_acc: 0.5050\n",
      "Epoch 8/70\n",
      "1000/1000 [==============================] - 7s - loss: 0.6566 - acc: 0.6120 - val_loss: 0.6906 - val_acc: 0.5250\n",
      "Epoch 9/70\n",
      "1000/1000 [==============================] - 7s - loss: 0.6512 - acc: 0.6270 - val_loss: 0.6901 - val_acc: 0.5200\n",
      "Epoch 10/70\n",
      "1000/1000 [==============================] - 7s - loss: 0.6441 - acc: 0.6410 - val_loss: 0.6891 - val_acc: 0.5330\n",
      "Epoch 11/70\n",
      "1000/1000 [==============================] - 7s - loss: 0.6328 - acc: 0.6520 - val_loss: 0.6880 - val_acc: 0.5350\n",
      "Epoch 12/70\n",
      "1000/1000 [==============================] - 7s - loss: 0.6163 - acc: 0.6640 - val_loss: 0.6870 - val_acc: 0.5530\n",
      "Epoch 13/70\n",
      "1000/1000 [==============================] - 7s - loss: 0.6044 - acc: 0.6680 - val_loss: 0.6847 - val_acc: 0.5740\n",
      "Epoch 14/70\n",
      "1000/1000 [==============================] - 7s - loss: 0.5913 - acc: 0.6900 - val_loss: 0.6828 - val_acc: 0.5750\n",
      "Epoch 15/70\n",
      "1000/1000 [==============================] - 7s - loss: 0.5789 - acc: 0.6890 - val_loss: 0.6791 - val_acc: 0.5770\n",
      "Epoch 16/70\n",
      "1000/1000 [==============================] - 7s - loss: 0.5706 - acc: 0.7030 - val_loss: 0.6761 - val_acc: 0.5770\n",
      "Epoch 17/70\n",
      "1000/1000 [==============================] - 7s - loss: 0.5507 - acc: 0.7300 - val_loss: 0.6722 - val_acc: 0.5880\n",
      "Epoch 18/70\n",
      "1000/1000 [==============================] - 7s - loss: 0.5534 - acc: 0.7220 - val_loss: 0.6682 - val_acc: 0.6000\n",
      "Epoch 19/70\n",
      "1000/1000 [==============================] - 7s - loss: 0.5294 - acc: 0.7420 - val_loss: 0.6617 - val_acc: 0.6310\n",
      "Epoch 20/70\n",
      "1000/1000 [==============================] - 7s - loss: 0.5072 - acc: 0.7590 - val_loss: 0.6563 - val_acc: 0.6040\n",
      "Epoch 21/70\n",
      "1000/1000 [==============================] - 7s - loss: 0.5016 - acc: 0.7510 - val_loss: 0.6482 - val_acc: 0.6500\n",
      "Epoch 22/70\n",
      "1000/1000 [==============================] - 7s - loss: 0.4964 - acc: 0.7470 - val_loss: 0.6435 - val_acc: 0.6270\n",
      "Epoch 23/70\n",
      "1000/1000 [==============================] - 7s - loss: 0.4725 - acc: 0.7800 - val_loss: 0.6381 - val_acc: 0.6270\n",
      "Epoch 24/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 7s - loss: 0.4617 - acc: 0.7730 - val_loss: 0.6322 - val_acc: 0.6270\n",
      "Epoch 25/70\n",
      "1000/1000 [==============================] - 7s - loss: 0.4524 - acc: 0.7890 - val_loss: 0.6232 - val_acc: 0.6500\n",
      "Epoch 26/70\n",
      "1000/1000 [==============================] - 7s - loss: 0.4130 - acc: 0.7970 - val_loss: 0.6121 - val_acc: 0.6840\n",
      "Epoch 27/70\n",
      "1000/1000 [==============================] - 7s - loss: 0.4091 - acc: 0.8070 - val_loss: 0.6047 - val_acc: 0.6790\n",
      "Epoch 28/70\n",
      "1000/1000 [==============================] - 7s - loss: 0.3799 - acc: 0.8300 - val_loss: 0.5864 - val_acc: 0.7670\n",
      "Epoch 29/70\n",
      "1000/1000 [==============================] - 7s - loss: 0.3692 - acc: 0.8350 - val_loss: 0.5905 - val_acc: 0.7180\n",
      "Epoch 30/70\n",
      "1000/1000 [==============================] - 7s - loss: 0.3110 - acc: 0.8820 - val_loss: 0.5807 - val_acc: 0.7050\n",
      "Epoch 31/70\n",
      "1000/1000 [==============================] - 7s - loss: 0.3561 - acc: 0.8360 - val_loss: 0.5655 - val_acc: 0.7450\n",
      "Epoch 32/70\n",
      "1000/1000 [==============================] - 7s - loss: 0.3106 - acc: 0.8720 - val_loss: 0.5475 - val_acc: 0.8120\n",
      "Epoch 33/70\n",
      "1000/1000 [==============================] - 7s - loss: 0.3055 - acc: 0.8690 - val_loss: 0.5451 - val_acc: 0.7800\n",
      "Epoch 34/70\n",
      "1000/1000 [==============================] - 8s - loss: 0.3002 - acc: 0.8700 - val_loss: 0.5354 - val_acc: 0.7960\n",
      "Epoch 35/70\n",
      "1000/1000 [==============================] - 8s - loss: 0.2749 - acc: 0.8930 - val_loss: 0.5226 - val_acc: 0.8360\n",
      "Epoch 36/70\n",
      "1000/1000 [==============================] - 7s - loss: 0.2628 - acc: 0.9060 - val_loss: 0.5183 - val_acc: 0.8100\n",
      "Epoch 37/70\n",
      "1000/1000 [==============================] - 7s - loss: 0.2384 - acc: 0.9120 - val_loss: 0.5010 - val_acc: 0.8480\n",
      "Epoch 38/70\n",
      "1000/1000 [==============================] - 7s - loss: 0.2235 - acc: 0.9120 - val_loss: 0.5034 - val_acc: 0.8210\n",
      "Epoch 39/70\n",
      "1000/1000 [==============================] - 7s - loss: 0.2023 - acc: 0.9300 - val_loss: 0.4854 - val_acc: 0.8330\n",
      "Epoch 40/70\n",
      "1000/1000 [==============================] - 7s - loss: 0.2208 - acc: 0.9250 - val_loss: 0.4744 - val_acc: 0.8600\n",
      "Epoch 41/70\n",
      "1000/1000 [==============================] - 7s - loss: 0.1821 - acc: 0.9330 - val_loss: 0.4748 - val_acc: 0.8530\n",
      "Epoch 42/70\n",
      "1000/1000 [==============================] - 8s - loss: 0.1567 - acc: 0.9440 - val_loss: 0.4687 - val_acc: 0.8490\n",
      "Epoch 43/70\n",
      "1000/1000 [==============================] - 7s - loss: 0.1643 - acc: 0.9440 - val_loss: 0.4457 - val_acc: 0.8830\n",
      "Epoch 44/70\n",
      "1000/1000 [==============================] - 8s - loss: 0.1711 - acc: 0.9400 - val_loss: 0.4350 - val_acc: 0.9060\n",
      "Epoch 45/70\n",
      "1000/1000 [==============================] - 7s - loss: 0.1556 - acc: 0.9460 - val_loss: 0.4359 - val_acc: 0.9150\n",
      "Epoch 46/70\n",
      "1000/1000 [==============================] - 7s - loss: 0.1495 - acc: 0.9460 - val_loss: 0.4279 - val_acc: 0.9090\n",
      "Epoch 47/70\n",
      "1000/1000 [==============================] - 7s - loss: 0.1375 - acc: 0.9530 - val_loss: 0.4245 - val_acc: 0.8970\n",
      "Epoch 48/70\n",
      "1000/1000 [==============================] - 7s - loss: 0.1353 - acc: 0.9560 - val_loss: 0.4024 - val_acc: 0.9370\n",
      "Epoch 49/70\n",
      "1000/1000 [==============================] - 7s - loss: 0.1154 - acc: 0.9590 - val_loss: 0.3992 - val_acc: 0.9290\n",
      "Epoch 50/70\n",
      "1000/1000 [==============================] - 7s - loss: 0.1163 - acc: 0.9590 - val_loss: 0.3881 - val_acc: 0.9400\n",
      "Epoch 51/70\n",
      "1000/1000 [==============================] - 7s - loss: 0.1119 - acc: 0.9580 - val_loss: 0.3885 - val_acc: 0.9300\n",
      "Epoch 52/70\n",
      "1000/1000 [==============================] - 7s - loss: 0.0923 - acc: 0.9700 - val_loss: 0.3852 - val_acc: 0.9220\n",
      "Epoch 53/70\n",
      "1000/1000 [==============================] - 7s - loss: 0.1059 - acc: 0.9660 - val_loss: 0.3699 - val_acc: 0.9380\n",
      "Epoch 54/70\n",
      "1000/1000 [==============================] - 8s - loss: 0.0945 - acc: 0.9710 - val_loss: 0.3623 - val_acc: 0.9380\n",
      "Epoch 55/70\n",
      "1000/1000 [==============================] - 7s - loss: 0.0871 - acc: 0.9720 - val_loss: 0.3645 - val_acc: 0.9330\n",
      "Epoch 56/70\n",
      "1000/1000 [==============================] - 7s - loss: 0.0928 - acc: 0.9730 - val_loss: 0.3569 - val_acc: 0.9330\n",
      "Epoch 57/70\n",
      "1000/1000 [==============================] - 8s - loss: 0.0717 - acc: 0.9770 - val_loss: 0.3488 - val_acc: 0.9380\n",
      "Epoch 58/70\n",
      "1000/1000 [==============================] - 7s - loss: 0.0598 - acc: 0.9820 - val_loss: 0.3472 - val_acc: 0.9360\n",
      "Epoch 59/70\n",
      "1000/1000 [==============================] - 7s - loss: 0.0727 - acc: 0.9760 - val_loss: 0.3175 - val_acc: 0.9680\n",
      "Epoch 60/70\n",
      "1000/1000 [==============================] - 7s - loss: 0.0622 - acc: 0.9830 - val_loss: 0.3216 - val_acc: 0.9550\n",
      "Epoch 61/70\n",
      "1000/1000 [==============================] - 7s - loss: 0.0619 - acc: 0.9840 - val_loss: 0.3154 - val_acc: 0.9670\n",
      "Epoch 62/70\n",
      "1000/1000 [==============================] - 7s - loss: 0.0637 - acc: 0.9830 - val_loss: 0.2976 - val_acc: 0.9710\n",
      "Epoch 63/70\n",
      "1000/1000 [==============================] - 7s - loss: 0.0586 - acc: 0.9890 - val_loss: 0.2985 - val_acc: 0.9720\n",
      "Epoch 64/70\n",
      "1000/1000 [==============================] - 7s - loss: 0.0543 - acc: 0.9860 - val_loss: 0.3053 - val_acc: 0.9580\n",
      "Epoch 65/70\n",
      "1000/1000 [==============================] - 7s - loss: 0.0535 - acc: 0.9850 - val_loss: 0.2942 - val_acc: 0.9610\n",
      "Epoch 66/70\n",
      "1000/1000 [==============================] - 7s - loss: 0.0417 - acc: 0.9880 - val_loss: 0.3037 - val_acc: 0.9440\n",
      "Epoch 67/70\n",
      "1000/1000 [==============================] - 7s - loss: 0.0529 - acc: 0.9850 - val_loss: 0.3067 - val_acc: 0.9310\n",
      "Epoch 68/70\n",
      "1000/1000 [==============================] - 7s - loss: 0.0462 - acc: 0.9890 - val_loss: 0.2851 - val_acc: 0.9630\n",
      "Epoch 69/70\n",
      "1000/1000 [==============================] - 7s - loss: 0.0279 - acc: 0.9970 - val_loss: 0.2857 - val_acc: 0.9570\n",
      "Epoch 70/70\n",
      "1000/1000 [==============================] - 7s - loss: 0.0377 - acc: 0.9950 - val_loss: 0.2757 - val_acc: 0.9550\n"
     ]
    }
   ],
   "source": [
    "historySR = networkSR.fit(\n",
    "            imagesTr, SRlabelsTr,\n",
    "            batch_size=50, epochs=70, shuffle=False) \n",
    "\n",
    "historySD = networkSD.fit(\n",
    "            imagesTr, SDlabelsTr,\n",
    "            batch_size=50, epochs=70, shuffle=False) \n",
    "\n",
    "historySiam = siamNetSD.fit(\n",
    "            [imagesTrNewR, imagesTrNewL], [SDlabelsTrSiam],\n",
    "            batch_size=50, epochs=70, validation_split=0.0, shuffle=False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "networkSR.save(\"networkSR.h5\")\n",
    "networkSD.save(\"siamNetSD.h5\")\n",
    "siamNetSD.save(\"siamNetSD.h5\")\n",
    "\n",
    "# networkSR = load_model('networkSR.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "0.999\n"
     ]
    }
   ],
   "source": [
    "perfSR=[]\n",
    "perfSD=[]\n",
    "predSD = networkSD.predict(imagesTe)\n",
    "predSD=np.around(predSD)\n",
    "resTeSD=np.subtract(SDlabelsTe.flatten(),predSD.flatten())\n",
    "perfSD.append(1-sum(abs(resTeSD))/len(resTeSD))\n",
    "\n",
    "predSR = networkSR.predict(imagesTe)\n",
    "predSR=np.around(predSR)\n",
    "resTeSR=np.subtract(SRlabelsTe.flatten(),predSR.flatten())\n",
    "perfSR.append(1-sum(abs(resTeSR))/len(resTeSR))\n",
    "\n",
    "print(np.mean(perfSD))\n",
    "print(np.mean(perfSR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.958\n"
     ]
    }
   ],
   "source": [
    "perfSDsia=[]\n",
    "predSDsia = siamNetSD.predict([imagesTeNewR,imagesTeNewL])\n",
    "predSDsia=np.around(predSDsia)\n",
    "resTeSDsia=np.subtract(SDlabelsTeSiam.flatten(),predSDsia.flatten())\n",
    "perfSDsia.append(1-sum(abs(resTeSDsia))/len(resTeSDsia))\n",
    "print(np.mean(perfSDsia))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we save all the results for further analysis in Matlab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sio.savemat('perfSR01.mat', mdict={'perfSR':perfSR})\n",
    "sio.savemat('perfSD01.mat', mdict={'perfSD':perfSD})\n",
    "\n",
    "historyAccSR=historySR.history['acc']\n",
    "historyAccSD=historySD.history['acc']\n",
    "\n",
    "sio.savemat('historyAccSR01.mat', mdict={'historyAccSR':historyAccSR})\n",
    "sio.savemat('historyAccSD01.mat', mdict={'historyAccSD':historyAccSD})\n",
    "\n",
    "\n",
    "sio.savemat('perfSD10sia.mat', mdict={'perfSDsia':perfSDsia})\n",
    "\n",
    "historyAccSDsia=historySiam.history['acc']\n",
    "\n",
    "sio.savemat('historyAccSDsia10.mat', mdict={'historyAccSDsia':historyAccSDsia})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
