{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SD - SR "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following notebook allows to replicate the simulation as describe in Alamia et al. (2019). CNN and a Siamese networks are compared when performing identity (SD) and Spatial Relationship (SR) tasks. See Alamia et al. (2019) for further details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After having imported a bunch of packages, we load the data from a previously genereated Matlab file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import time\n",
    "import csv\n",
    "from keras.layers.core import Dense, Activation, Dropout, Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers import MaxPooling2D, Conv2D, ZeroPadding2D, Activation, Input, concatenate, Add, Multiply\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras import regularizers, optimizers\n",
    "from keras.utils import np_utils\n",
    "np.random.seed(1234)\n",
    "\n",
    "import tensorflow as tf \n",
    "import keras\n",
    "from keras.layers.merge import _Merge\n",
    "\n",
    "import scipy.io as sio\n",
    "from scipy import stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getImagesNlabelsSiam() :\n",
    "\n",
    "    infile = sio.loadmat('siamese1000val.mat')\n",
    "    \n",
    "    allTrialsTr = infile.get('allTrialsTr')\n",
    "    SRconditionsTr=infile.get('SRconditionsTr')\n",
    "    SDconditionsTr=infile.get('SDconditionsTr')\n",
    "    \n",
    "    allTrialsVal = infile.get('allTrialsVal')\n",
    "    SRconditionsVal=infile.get('SRconditionsVal')\n",
    "    SDconditionsVal=infile.get('SDconditionsVal')\n",
    "    \n",
    "    allTrialsTe = infile.get('allTrialsTe')\n",
    "    SRconditionsTe=infile.get('SRconditionsTe')\n",
    "    SDconditionsTe=infile.get('SDconditionsTe')\n",
    "\n",
    "    #shuffling training\n",
    "    perm = np.arange(allTrialsTr.shape[3])  \n",
    "    np.random.shuffle(perm)  \n",
    "    allTrialsTrPerm = allTrialsTr[:,:,:,perm] \n",
    "    SRconditionsTrPerm = SRconditionsTr[:,perm] \n",
    "    SDconditionsTrPerm = SDconditionsTr[:,perm] \n",
    "   \n",
    "    #providing it with the right dimensions  training\n",
    "    allTrialsTrRearranged=np.moveaxis(allTrialsTrPerm,-1,0)\n",
    "    SDconditionsTrRearranged=np.moveaxis(SDconditionsTrPerm,-1,0)\n",
    "    SRconditionsTrRearranged=np.moveaxis(SRconditionsTrPerm,-1,0)\n",
    "    allTrialsTrRearranged2 = np.expand_dims(allTrialsTrRearranged,axis=-1)\n",
    "    allTrialsTrRearranged2 = allTrialsTrRearranged\n",
    "    \n",
    "    \n",
    "    #shuffling validation\n",
    "    perm = np.arange(allTrialsVal.shape[3])  \n",
    "    np.random.shuffle(perm)  \n",
    "    allTrialsValPerm = allTrialsVal[:,:,:,perm] \n",
    "    SRconditionsValPerm = SRconditionsVal[:,perm] \n",
    "    SDconditionsValPerm = SDconditionsVal[:,perm] \n",
    "   \n",
    "    #providing it with the right dimensions validation\n",
    "    allTrialsValRearranged=np.moveaxis(allTrialsValPerm,-1,0)\n",
    "    SDconditionsValRearranged=np.moveaxis(SDconditionsValPerm,-1,0)\n",
    "    SRconditionsValRearranged=np.moveaxis(SRconditionsValPerm,-1,0)\n",
    "    allTrialsValRearranged2 = np.expand_dims(allTrialsValRearranged,axis=-1)\n",
    "    allTrialsValRearranged2 = allTrialsValRearranged\n",
    "    \n",
    "    \n",
    "    #shuffling testing\n",
    "    perm = np.arange(allTrialsTe.shape[3])  \n",
    "    np.random.shuffle(perm)  \n",
    "    allTrialsTePerm = allTrialsTe[:,:,:,perm] \n",
    "    SRconditionsTePerm = SRconditionsTe[:,perm] \n",
    "    SDconditionsTePerm = SDconditionsTe[:,perm] \n",
    "   \n",
    "    #providing it with the right dimensions  testing\n",
    "    allTrialsTeRearranged=np.moveaxis(allTrialsTePerm,-1,0)\n",
    "    SDconditionsTeRearranged=np.moveaxis(SDconditionsTePerm,-1,0)\n",
    "    SRconditionsTeRearranged=np.moveaxis(SRconditionsTePerm,-1,0)\n",
    "    allTrialsTeRearranged2 = np.expand_dims(allTrialsTeRearranged,axis=-1)\n",
    "    allTrialsTeRearranged2 = allTrialsTeRearranged\n",
    "    \n",
    "    return {'imagesTr':allTrialsTrRearranged2,'SRlabelsTr':SRconditionsTrRearranged,'SDlabelsTr':SDconditionsTrRearranged,'imagesVal':allTrialsValRearranged2,'SRlabelsVal':SRconditionsValRearranged,'SDlabelsVal':SDconditionsValRearranged,'imagesTe':allTrialsTeRearranged2,'SRlabelsTe':SRconditionsTeRearranged,'SDlabelsTe':SDconditionsTeRearranged}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getImagesNlabels() :\n",
    "\n",
    "    #infile = sio.loadmat('artVisDataset.mat')\n",
    "    infile = sio.loadmat('cnn1000val.mat')\n",
    "\n",
    "    allTrialsTr = infile.get('allTrialsTr')\n",
    "    SRconditionsTr=infile.get('SRconditionsTr')\n",
    "    SDconditionsTr=infile.get('SDconditionsTr')\n",
    "    \n",
    "    allTrialsVal = infile.get('allTrialsVal')\n",
    "    SRconditionsVal=infile.get('SRconditionsVal')\n",
    "    SDconditionsVal=infile.get('SDconditionsVal')\n",
    "    \n",
    "    allTrialsTe = infile.get('allTrialsTe')\n",
    "    SRconditionsTe=infile.get('SRconditionsTe')\n",
    "    SDconditionsTe=infile.get('SDconditionsTe')\n",
    "    \n",
    "\n",
    "    #shuffling training\n",
    "    perm = np.arange(allTrialsTr.shape[2])  \n",
    "    np.random.shuffle(perm)  \n",
    "    allTrialsTrPerm = allTrialsTr[:,:,perm] \n",
    "    SRconditionsTrPerm = SRconditionsTr[:,perm] \n",
    "    SDconditionsTrPerm = SDconditionsTr[:,perm] \n",
    "   \n",
    "    #providing it with the right dimensions  training\n",
    "    allTrialsTrRearranged=np.moveaxis(allTrialsTrPerm,-1,0)\n",
    "    SDconditionsTrRearranged=np.moveaxis(SDconditionsTrPerm,-1,0)\n",
    "    SRconditionsTrRearranged=np.moveaxis(SRconditionsTrPerm,-1,0)\n",
    "    allTrialsTrRearranged2 = np.expand_dims(allTrialsTrRearranged,axis=-1)\n",
    "    \n",
    "        \n",
    "    #shuffling validation\n",
    "    perm = np.arange(allTrialsVal.shape[2])  \n",
    "    np.random.shuffle(perm)  \n",
    "    allTrialsValPerm = allTrialsVal[:,:,perm] \n",
    "    SRconditionsValPerm = SRconditionsVal[:,perm] \n",
    "    SDconditionsValPerm = SDconditionsVal[:,perm] \n",
    "   \n",
    "    #providing it with the right dimensions validation\n",
    "    allTrialsValRearranged=np.moveaxis(allTrialsValPerm,-1,0)\n",
    "    SDconditionsValRearranged=np.moveaxis(SDconditionsValPerm,-1,0)\n",
    "    SRconditionsValRearranged=np.moveaxis(SRconditionsValPerm,-1,0)\n",
    "    allTrialsValRearranged2 = np.expand_dims(allTrialsValRearranged,axis=-1)\n",
    "    allTrialsValRearranged2 = allTrialsValRearranged\n",
    "    \n",
    "    \n",
    "    #shuffling testing\n",
    "    perm = np.arange(allTrialsTe.shape[2])  \n",
    "    np.random.shuffle(perm)  \n",
    "    allTrialsTePerm = allTrialsTe[:,:,perm] \n",
    "    SRconditionsTePerm = SRconditionsTe[:,perm] \n",
    "    SDconditionsTePerm = SDconditionsTe[:,perm] \n",
    "   \n",
    "    #providing it with the right dimensions  testing\n",
    "    allTrialsTeRearranged=np.moveaxis(allTrialsTePerm,-1,0)\n",
    "    SDconditionsTeRearranged=np.moveaxis(SDconditionsTePerm,-1,0)\n",
    "    SRconditionsTeRearranged=np.moveaxis(SRconditionsTePerm,-1,0)\n",
    "    allTrialsTeRearranged2 = np.expand_dims(allTrialsTeRearranged,axis=-1)\n",
    "    \n",
    "    return {'imagesTr':allTrialsTrRearranged2,'SRlabelsTr':SRconditionsTrRearranged,'SDlabelsTr':SDconditionsTrRearranged,'imagesTe':allTrialsTeRearranged2,'SRlabelsTe':SRconditionsTeRearranged,'SDlabelsTe':SDconditionsTeRearranged}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next two cells we define the Siamese Network and the convolutional one. Note that in the Siamese network we redefine the class Substract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Subtract(_Merge):\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(Subtract, self).build(input_shape)\n",
    "        if len(input_shape) != 2:\n",
    "            raise ValueError('A `Subtract` layer should be called '\n",
    "                             'on exactly 2 inputs')\n",
    "\n",
    "    def _merge_function(self, inputs):\n",
    "        if len(inputs) != 2:\n",
    "            raise ValueError('A `Subtract` layer should be called '\n",
    "                             'on exactly 2 inputs')\n",
    "        return inputs[0] - inputs[1]\n",
    "\n",
    "\n",
    "def get_siamese_model(images):\n",
    "\n",
    "    # Define the tensors for the two input images\n",
    "#     left_input = Input(images[:,:,:,0].shape)\n",
    "#     right_input = Input(images[:,:,:,1].shape)\n",
    "#     left_input = np.expand_dims(left_input,axis=-1)\n",
    "#     right_input = np.expand_dims(right_input,axis=-1)\n",
    "#     left_input = Input(left_input.shape)\n",
    "#     right_input = Input(right_input.shape)\n",
    "    \n",
    "    input_shape = (images.shape[1], images.shape[2], 1)\n",
    "    left_input = Input(input_shape)\n",
    "    right_input = Input(input_shape)\n",
    "    \n",
    "    \n",
    "    # Convolutional Neural Network\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(4, (2, 2), strides=1, input_shape=(images.shape[1], images.shape[2], 1), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=1))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Conv2D(4, (2, 2), strides=1, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=1))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Conv2D(4, (2, 2), strides=1, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=1))   \n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Conv2D(4, (2, 2), strides=1, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=1))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Conv2D(4, (2, 2), strides=1, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=1))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Conv2D(4, (2, 2), strides=1, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=1))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    # Generate the encodings (feature vectors) for the two images\n",
    "    encoded_l = model(left_input)\n",
    "    encoded_r = model(right_input)\n",
    "    \n",
    "    combineFeatures2 = Subtract()([encoded_l, encoded_r])\n",
    "    \n",
    "    # Add a dense layer with a sigmoid unit to generate the similarity score\n",
    "    prediction1 = Dense(128,activation='relu')(combineFeatures2)\n",
    "    prediction1do = Dropout(.3)(prediction1)\n",
    "    prediction2 = Dense(128,activation='relu')(prediction1)\n",
    "    prediction2do = Dropout(.3)(prediction2)\n",
    "    prediction = Dense(1,activation='sigmoid')(prediction2do)\n",
    "    \n",
    "    # Connect the inputs with the outputs\n",
    "    siamese_net = Model(inputs=[left_input,right_input],outputs=prediction)\n",
    "    \n",
    "    siamese_net.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=optimizers.Adam(lr=0.0001))\n",
    "    \n",
    "    # return the model\n",
    "    return siamese_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def buildingTheNetwork(images) :\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(4, (2, 2), strides=1, input_shape=(images.shape[1], images.shape[2], 1), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=1))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(4, (2, 2), strides=1, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=1))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(4, (2, 2), strides=1, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=1))   \n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(4, (2, 2), strides=1, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=1))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(4, (2, 2), strides=1, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=1))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(4, (2, 2), strides=1, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=1))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(4, (2, 2), strides=1, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=1))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=optimizers.Adam(lr=0.0001),)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we finally run the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 49, 49, 4)         20        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 48, 48, 4)         0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 48, 48, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 47, 47, 4)         68        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 46, 46, 4)         0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 46, 46, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 45, 45, 4)         68        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 44, 44, 4)         0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 44, 44, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 43, 43, 4)         68        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 42, 42, 4)         0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 42, 42, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 41, 41, 4)         68        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 40, 40, 4)         0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 40, 40, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 39, 39, 4)         68        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 38, 38, 4)         0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 38, 38, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 37, 37, 4)         68        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 36, 36, 4)         0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 36, 36, 4)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 5184)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               663680    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 129       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 680,749.0\n",
      "Trainable params: 680,749.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 49, 49, 4)         20        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 48, 48, 4)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 48, 48, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 47, 47, 4)         68        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 46, 46, 4)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 46, 46, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 45, 45, 4)         68        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 44, 44, 4)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 44, 44, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 43, 43, 4)         68        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 42, 42, 4)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 42, 42, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 41, 41, 4)         68        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 40, 40, 4)         0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 40, 40, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 39, 39, 4)         68        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 38, 38, 4)         0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 38, 38, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 37, 37, 4)         68        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 36, 36, 4)         0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 36, 36, 4)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 5184)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               663680    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 129       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 680,749.0\n",
      "Trainable params: 680,749.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 50, 50, 1)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_2 (InputLayer)             (None, 50, 50, 1)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "sequential_3 (Sequential)        (None, 5776)          360                                          \n",
      "____________________________________________________________________________________________________\n",
      "subtract_1 (Subtract)            (None, 5776)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_7 (Dense)                  (None, 128)           739456                                       \n",
      "____________________________________________________________________________________________________\n",
      "dense_8 (Dense)                  (None, 128)           16512                                        \n",
      "____________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)             (None, 128)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_9 (Dense)                  (None, 1)             129                                          \n",
      "====================================================================================================\n",
      "Total params: 756,457.0\n",
      "Trainable params: 756,457.0\n",
      "Non-trainable params: 0.0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "data=getImagesNlabels() \n",
    "imagesTr=data['imagesTr']\n",
    "SRlabelsTr=data['SRlabelsTr']\n",
    "SDlabelsTr=data['SDlabelsTr']\n",
    "\n",
    "imagesTe=data['imagesTe']\n",
    "SRlabelsTe=data['SRlabelsTe']\n",
    "SDlabelsTe=data['SDlabelsTe']\n",
    "\n",
    "\n",
    "dataSiam=getImagesNlabelsSiam() \n",
    "imagesTrSiam=dataSiam['imagesTr']\n",
    "SRlabelsTrSiam=dataSiam['SRlabelsTr']\n",
    "SDlabelsTrSiam=dataSiam['SDlabelsTr']\n",
    "\n",
    "imagesValSiam=dataSiam['imagesVal']\n",
    "SRlabelsValSiam=dataSiam['SRlabelsVal']\n",
    "SDlabelsValSiam=dataSiam['SDlabelsVal']\n",
    "\n",
    "imagesTeSiam=dataSiam['imagesTe']\n",
    "SRlabelsTeSiam=dataSiam['SRlabelsTe']\n",
    "SDlabelsTeSiam=dataSiam['SDlabelsTe']\n",
    "\n",
    "\n",
    "imagesTrNewL=imagesTrSiam[:,:,:,0]\n",
    "imagesTrNewR=imagesTrSiam[:,:,:,1]\n",
    "imagesTrNewL = np.expand_dims(imagesTrNewL,axis=-1)\n",
    "imagesTrNewR = np.expand_dims(imagesTrNewR,axis=-1)\n",
    "\n",
    "imagesValNewL=imagesValSiam[:,:,:,0]\n",
    "imagesValNewR=imagesValSiam[:,:,:,1]\n",
    "imagesValNewL = np.expand_dims(imagesValNewL,axis=-1)\n",
    "imagesValNewR = np.expand_dims(imagesValNewR,axis=-1)\n",
    "\n",
    "imagesTeNewL=imagesTeSiam[:,:,:,0]\n",
    "imagesTeNewR=imagesTeSiam[:,:,:,1]\n",
    "imagesTeNewL = np.expand_dims(imagesTeNewL,axis=-1)\n",
    "imagesTeNewR = np.expand_dims(imagesTeNewR,axis=-1)\n",
    "\n",
    "networkSR=buildingTheNetwork(imagesTr) \n",
    "networkSD=buildingTheNetwork(imagesTr) \n",
    "\n",
    "siamNetSD=get_siamese_model(imagesTrSiam) \n",
    "\n",
    "networkSD.summary()\n",
    "networkSR.summary()\n",
    "siamNetSD.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and finally we fit the models!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.6033 - acc: 0.8800     \n",
      "Epoch 2/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.4472 - acc: 0.9270     \n",
      "Epoch 3/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.2683 - acc: 0.9320     \n",
      "Epoch 4/70\n",
      "1000/1000 [==============================] - 4s - loss: 0.1780 - acc: 0.9440     \n",
      "Epoch 5/70\n",
      "1000/1000 [==============================] - 4s - loss: 0.1316 - acc: 0.9580     \n",
      "Epoch 6/70\n",
      "1000/1000 [==============================] - 4s - loss: 0.0893 - acc: 0.9740     \n",
      "Epoch 7/70\n",
      "1000/1000 [==============================] - 4s - loss: 0.0608 - acc: 0.9850     \n",
      "Epoch 8/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.0458 - acc: 0.9920     \n",
      "Epoch 9/70\n",
      "1000/1000 [==============================] - 4s - loss: 0.0374 - acc: 0.9910     \n",
      "Epoch 10/70\n",
      "1000/1000 [==============================] - 4s - loss: 0.0351 - acc: 0.9890     \n",
      "Epoch 11/70\n",
      "1000/1000 [==============================] - 4s - loss: 0.0220 - acc: 0.9960     \n",
      "Epoch 12/70\n",
      "1000/1000 [==============================] - 4s - loss: 0.0198 - acc: 0.9960     \n",
      "Epoch 13/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.0114 - acc: 0.9990     \n",
      "Epoch 14/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.0115 - acc: 0.9970     \n",
      "Epoch 15/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.0078 - acc: 1.0000     \n",
      "Epoch 16/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.0067 - acc: 1.0000     \n",
      "Epoch 17/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.0043 - acc: 1.0000     \n",
      "Epoch 18/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.0062 - acc: 0.9980     \n",
      "Epoch 19/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.0029 - acc: 1.0000     \n",
      "Epoch 20/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.0039 - acc: 1.0000     \n",
      "Epoch 21/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.0026 - acc: 1.0000     \n",
      "Epoch 22/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.0024 - acc: 1.0000     \n",
      "Epoch 23/70\n",
      "1000/1000 [==============================] - 4s - loss: 0.0026 - acc: 1.0000     \n",
      "Epoch 24/70\n",
      "1000/1000 [==============================] - 4s - loss: 0.0036 - acc: 0.9990     \n",
      "Epoch 25/70\n",
      "1000/1000 [==============================] - 4s - loss: 0.0023 - acc: 1.0000     \n",
      "Epoch 26/70\n",
      "1000/1000 [==============================] - 4s - loss: 0.0015 - acc: 1.0000     \n",
      "Epoch 27/70\n",
      "1000/1000 [==============================] - 4s - loss: 0.0014 - acc: 1.0000     \n",
      "Epoch 28/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.0010 - acc: 1.0000     \n",
      "Epoch 29/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.0013 - acc: 1.0000     \n",
      "Epoch 30/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.0022 - acc: 0.9990        \n",
      "Epoch 31/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.0014 - acc: 1.0000     \n",
      "Epoch 32/70\n",
      "1000/1000 [==============================] - 3s - loss: 9.1807e-04 - acc: 1.0000     \n",
      "Epoch 33/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.0017 - acc: 1.0000     \n",
      "Epoch 34/70\n",
      "1000/1000 [==============================] - 3s - loss: 6.9475e-04 - acc: 1.0000     \n",
      "Epoch 35/70\n",
      "1000/1000 [==============================] - 4s - loss: 6.1577e-04 - acc: 1.0000     \n",
      "Epoch 36/70\n",
      "1000/1000 [==============================] - 3s - loss: 3.6519e-04 - acc: 1.0000     \n",
      "Epoch 37/70\n",
      "1000/1000 [==============================] - 3s - loss: 6.6898e-04 - acc: 1.0000     \n",
      "Epoch 38/70\n",
      "1000/1000 [==============================] - 4s - loss: 3.9128e-04 - acc: 1.0000     \n",
      "Epoch 39/70\n",
      "1000/1000 [==============================] - 3s - loss: 4.3756e-04 - acc: 1.0000     \n",
      "Epoch 40/70\n",
      "1000/1000 [==============================] - 4s - loss: 4.4889e-04 - acc: 1.0000     \n",
      "Epoch 41/70\n",
      "1000/1000 [==============================] - 4s - loss: 4.4680e-04 - acc: 1.0000     \n",
      "Epoch 42/70\n",
      "1000/1000 [==============================] - 4s - loss: 4.9374e-04 - acc: 1.0000     \n",
      "Epoch 43/70\n",
      "1000/1000 [==============================] - 4s - loss: 5.1821e-04 - acc: 1.0000     \n",
      "Epoch 44/70\n",
      "1000/1000 [==============================] - 5s - loss: 4.5888e-04 - acc: 1.0000     \n",
      "Epoch 45/70\n",
      "1000/1000 [==============================] - 4s - loss: 3.6081e-04 - acc: 1.0000     \n",
      "Epoch 46/70\n",
      "1000/1000 [==============================] - 5s - loss: 4.7466e-04 - acc: 1.0000     - ETA: 2s - loss: 2.8734e-04 - a\n",
      "Epoch 47/70\n",
      "1000/1000 [==============================] - 4s - loss: 3.8664e-04 - acc: 1.0000     \n",
      "Epoch 48/70\n",
      "1000/1000 [==============================] - 5s - loss: 2.3000e-04 - acc: 1.0000     \n",
      "Epoch 49/70\n",
      "1000/1000 [==============================] - 4s - loss: 7.0258e-04 - acc: 1.0000     \n",
      "Epoch 50/70\n",
      "1000/1000 [==============================] - 4s - loss: 4.5403e-04 - acc: 1.0000     \n",
      "Epoch 51/70\n",
      "1000/1000 [==============================] - 4s - loss: 2.4853e-04 - acc: 1.0000     \n",
      "Epoch 52/70\n",
      "1000/1000 [==============================] - 3s - loss: 2.6756e-04 - acc: 1.0000     \n",
      "Epoch 53/70\n",
      "1000/1000 [==============================] - 3s - loss: 2.4183e-04 - acc: 1.0000     \n",
      "Epoch 54/70\n",
      "1000/1000 [==============================] - 4s - loss: 2.7506e-04 - acc: 1.0000     \n",
      "Epoch 55/70\n",
      "1000/1000 [==============================] - 4s - loss: 3.5218e-04 - acc: 1.0000     \n",
      "Epoch 56/70\n",
      "1000/1000 [==============================] - 4s - loss: 2.2474e-04 - acc: 1.0000     \n",
      "Epoch 57/70\n",
      "1000/1000 [==============================] - 3s - loss: 1.6365e-04 - acc: 1.0000     \n",
      "Epoch 58/70\n",
      "1000/1000 [==============================] - 4s - loss: 1.6490e-04 - acc: 1.0000     \n",
      "Epoch 59/70\n",
      "1000/1000 [==============================] - 4s - loss: 1.3042e-04 - acc: 1.0000     - ETA: 2s - loss: 1.1775e-04 - a\n",
      "Epoch 60/70\n",
      "1000/1000 [==============================] - 4s - loss: 1.4515e-04 - acc: 1.0000     \n",
      "Epoch 61/70\n",
      "1000/1000 [==============================] - 4s - loss: 2.2995e-04 - acc: 1.0000     \n",
      "Epoch 62/70\n",
      "1000/1000 [==============================] - 4s - loss: 1.9420e-04 - acc: 1.0000     \n",
      "Epoch 63/70\n",
      "1000/1000 [==============================] - 4s - loss: 2.1160e-04 - acc: 1.0000     \n",
      "Epoch 64/70\n",
      "1000/1000 [==============================] - 3s - loss: 1.2603e-04 - acc: 1.0000     \n",
      "Epoch 65/70\n",
      "1000/1000 [==============================] - 4s - loss: 1.1152e-04 - acc: 1.0000     \n",
      "Epoch 66/70\n",
      "1000/1000 [==============================] - 4s - loss: 2.9663e-04 - acc: 1.0000     \n",
      "Epoch 67/70\n",
      "1000/1000 [==============================] - 4s - loss: 1.2875e-04 - acc: 1.0000     \n",
      "Epoch 68/70\n",
      "1000/1000 [==============================] - 4s - loss: 1.0317e-04 - acc: 1.0000     \n",
      "Epoch 69/70\n",
      "1000/1000 [==============================] - 4s - loss: 7.3838e-05 - acc: 1.0000     \n",
      "Epoch 70/70\n",
      "1000/1000 [==============================] - 4s - loss: 6.9803e-05 - acc: 1.0000     \n",
      "Epoch 1/70\n",
      "1000/1000 [==============================] - 4s - loss: 0.6926 - acc: 0.5200     \n",
      "Epoch 2/70\n",
      "1000/1000 [==============================] - 4s - loss: 0.6879 - acc: 0.5650     \n",
      "Epoch 3/70\n",
      "1000/1000 [==============================] - 4s - loss: 0.6821 - acc: 0.5880     \n",
      "Epoch 4/70\n",
      "1000/1000 [==============================] - 4s - loss: 0.6774 - acc: 0.5980     \n",
      "Epoch 5/70\n",
      "1000/1000 [==============================] - 4s - loss: 0.6726 - acc: 0.5940     \n",
      "Epoch 6/70\n",
      "1000/1000 [==============================] - 4s - loss: 0.6617 - acc: 0.6330     \n",
      "Epoch 7/70\n",
      "1000/1000 [==============================] - 4s - loss: 0.6536 - acc: 0.6440     \n",
      "Epoch 8/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.6415 - acc: 0.6580     \n",
      "Epoch 9/70\n",
      "1000/1000 [==============================] - 4s - loss: 0.6308 - acc: 0.6720     \n",
      "Epoch 10/70\n",
      "1000/1000 [==============================] - 4s - loss: 0.6151 - acc: 0.7090     \n",
      "Epoch 11/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.5905 - acc: 0.7230     \n",
      "Epoch 12/70\n",
      "1000/1000 [==============================] - 4s - loss: 0.5708 - acc: 0.7220     \n",
      "Epoch 13/70\n",
      "1000/1000 [==============================] - 4s - loss: 0.5401 - acc: 0.7560     \n",
      "Epoch 14/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.5050 - acc: 0.7800     \n",
      "Epoch 15/70\n",
      "1000/1000 [==============================] - 4s - loss: 0.4811 - acc: 0.7690     \n",
      "Epoch 16/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 4s - loss: 0.4481 - acc: 0.7970     \n",
      "Epoch 17/70\n",
      "1000/1000 [==============================] - 4s - loss: 0.4072 - acc: 0.8340     \n",
      "Epoch 18/70\n",
      "1000/1000 [==============================] - 4s - loss: 0.3995 - acc: 0.8240     \n",
      "Epoch 19/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.3746 - acc: 0.8430     \n",
      "Epoch 20/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.3481 - acc: 0.8550     \n",
      "Epoch 21/70\n",
      "1000/1000 [==============================] - 4s - loss: 0.2967 - acc: 0.8800     \n",
      "Epoch 22/70\n",
      "1000/1000 [==============================] - 4s - loss: 0.2876 - acc: 0.8700     \n",
      "Epoch 23/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.2458 - acc: 0.9080     \n",
      "Epoch 24/70\n",
      "1000/1000 [==============================] - 4s - loss: 0.2483 - acc: 0.8960     \n",
      "Epoch 25/70\n",
      "1000/1000 [==============================] - 4s - loss: 0.2016 - acc: 0.9170     \n",
      "Epoch 26/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.2188 - acc: 0.9130     \n",
      "Epoch 27/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.1914 - acc: 0.9310     \n",
      "Epoch 28/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.1872 - acc: 0.9250     \n",
      "Epoch 29/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.1786 - acc: 0.9320     \n",
      "Epoch 30/70\n",
      "1000/1000 [==============================] - 5s - loss: 0.1555 - acc: 0.9450     \n",
      "Epoch 31/70\n",
      "1000/1000 [==============================] - 4s - loss: 0.1483 - acc: 0.9420     \n",
      "Epoch 32/70\n",
      "1000/1000 [==============================] - 4s - loss: 0.1487 - acc: 0.9340     \n",
      "Epoch 33/70\n",
      "1000/1000 [==============================] - 4s - loss: 0.1398 - acc: 0.9460     \n",
      "Epoch 34/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.1173 - acc: 0.9610     \n",
      "Epoch 35/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.1136 - acc: 0.9680     \n",
      "Epoch 36/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.1212 - acc: 0.9560     \n",
      "Epoch 37/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.1024 - acc: 0.9660     \n",
      "Epoch 38/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.1062 - acc: 0.9600     \n",
      "Epoch 39/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.0964 - acc: 0.9670     \n",
      "Epoch 40/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.0786 - acc: 0.9690     \n",
      "Epoch 41/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.0940 - acc: 0.9580     \n",
      "Epoch 42/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.0943 - acc: 0.9680     \n",
      "Epoch 43/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.0922 - acc: 0.9730     \n",
      "Epoch 44/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.0953 - acc: 0.9700     \n",
      "Epoch 45/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.0715 - acc: 0.9730     \n",
      "Epoch 46/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.0673 - acc: 0.9810     \n",
      "Epoch 47/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.0780 - acc: 0.9730     \n",
      "Epoch 48/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.0753 - acc: 0.9730     \n",
      "Epoch 49/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.0615 - acc: 0.9780     \n",
      "Epoch 50/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.0624 - acc: 0.9770     \n",
      "Epoch 51/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.0481 - acc: 0.9840     \n",
      "Epoch 52/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.0641 - acc: 0.9750     \n",
      "Epoch 53/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.0655 - acc: 0.9760     \n",
      "Epoch 54/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.0599 - acc: 0.9770     \n",
      "Epoch 55/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.0516 - acc: 0.9840     \n",
      "Epoch 56/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.0527 - acc: 0.9800     \n",
      "Epoch 57/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.0466 - acc: 0.9840     \n",
      "Epoch 58/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.0404 - acc: 0.9900     \n",
      "Epoch 59/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.0426 - acc: 0.9830     \n",
      "Epoch 60/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.0298 - acc: 0.9910     \n",
      "Epoch 61/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.0400 - acc: 0.9870     \n",
      "Epoch 62/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.0461 - acc: 0.9840     \n",
      "Epoch 63/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.0389 - acc: 0.9870     \n",
      "Epoch 64/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.0396 - acc: 0.9810     \n",
      "Epoch 65/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.0343 - acc: 0.9890     \n",
      "Epoch 66/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.0413 - acc: 0.9830     \n",
      "Epoch 67/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.0326 - acc: 0.9890     \n",
      "Epoch 68/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.0376 - acc: 0.9840     \n",
      "Epoch 69/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.0394 - acc: 0.9850     \n",
      "Epoch 70/70\n",
      "1000/1000 [==============================] - 3s - loss: 0.0368 - acc: 0.9870     \n",
      "Epoch 1/70\n",
      "1000/1000 [==============================] - 5s - loss: 0.0395 - acc: 0.9890     \n",
      "Epoch 2/70\n",
      "1000/1000 [==============================] - 5s - loss: 0.0297 - acc: 0.9930     \n",
      "Epoch 3/70\n",
      "1000/1000 [==============================] - 5s - loss: 0.0485 - acc: 0.9870     \n",
      "Epoch 4/70\n",
      "1000/1000 [==============================] - 5s - loss: 0.0354 - acc: 0.9910     \n",
      "Epoch 5/70\n",
      "1000/1000 [==============================] - 5s - loss: 0.0348 - acc: 0.9910     \n",
      "Epoch 6/70\n",
      "1000/1000 [==============================] - 5s - loss: 0.0348 - acc: 0.9930     \n",
      "Epoch 7/70\n",
      "1000/1000 [==============================] - 5s - loss: 0.0309 - acc: 0.9950     \n",
      "Epoch 8/70\n",
      "1000/1000 [==============================] - 5s - loss: 0.0300 - acc: 0.9920     \n",
      "Epoch 9/70\n",
      "1000/1000 [==============================] - 5s - loss: 0.0310 - acc: 0.9920     \n",
      "Epoch 10/70\n",
      "1000/1000 [==============================] - 5s - loss: 0.0346 - acc: 0.9920     \n",
      "Epoch 11/70\n",
      "1000/1000 [==============================] - 5s - loss: 0.0226 - acc: 0.9970     \n",
      "Epoch 12/70\n",
      "1000/1000 [==============================] - 5s - loss: 0.0237 - acc: 0.9920     \n",
      "Epoch 13/70\n",
      "1000/1000 [==============================] - 5s - loss: 0.0233 - acc: 0.9960     \n",
      "Epoch 14/70\n",
      "1000/1000 [==============================] - 5s - loss: 0.0193 - acc: 0.9970     \n",
      "Epoch 15/70\n",
      "1000/1000 [==============================] - 5s - loss: 0.0113 - acc: 0.9990     \n",
      "Epoch 16/70\n",
      "1000/1000 [==============================] - 5s - loss: 0.0186 - acc: 0.9960     \n",
      "Epoch 17/70\n",
      "1000/1000 [==============================] - 5s - loss: 0.0201 - acc: 0.9960     \n",
      "Epoch 18/70\n",
      "1000/1000 [==============================] - 5s - loss: 0.0206 - acc: 0.9950     \n",
      "Epoch 19/70\n",
      "1000/1000 [==============================] - 5s - loss: 0.0246 - acc: 0.9940     \n",
      "Epoch 20/70\n",
      "1000/1000 [==============================] - 5s - loss: 0.0134 - acc: 0.9980     \n",
      "Epoch 21/70\n",
      "1000/1000 [==============================] - 5s - loss: 0.0156 - acc: 0.9980     \n",
      "Epoch 22/70\n",
      "1000/1000 [==============================] - 5s - loss: 0.0239 - acc: 0.9950     \n",
      "Epoch 23/70\n",
      "1000/1000 [==============================] - 5s - loss: 0.0227 - acc: 0.9930     \n",
      "Epoch 24/70\n",
      "1000/1000 [==============================] - 5s - loss: 0.0125 - acc: 0.9980     \n",
      "Epoch 25/70\n",
      "1000/1000 [==============================] - 5s - loss: 0.0111 - acc: 0.9980     \n",
      "Epoch 26/70\n",
      "1000/1000 [==============================] - 5s - loss: 0.0220 - acc: 0.9940     \n",
      "Epoch 27/70\n",
      "1000/1000 [==============================] - 5s - loss: 0.0172 - acc: 0.9950     \n",
      "Epoch 28/70\n",
      "1000/1000 [==============================] - 5s - loss: 0.0088 - acc: 0.9990     \n",
      "Epoch 29/70\n",
      "1000/1000 [==============================] - 5s - loss: 0.0214 - acc: 0.9960     \n",
      "Epoch 30/70\n",
      "1000/1000 [==============================] - 5s - loss: 0.0069 - acc: 0.9990     \n",
      "Epoch 31/70\n",
      "1000/1000 [==============================] - 5s - loss: 0.0106 - acc: 0.9990     \n",
      "Epoch 32/70\n",
      "1000/1000 [==============================] - 5s - loss: 0.0082 - acc: 0.9980     \n",
      "Epoch 33/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 5s - loss: 0.0156 - acc: 0.9960     \n",
      "Epoch 34/70\n",
      "1000/1000 [==============================] - 5s - loss: 0.0205 - acc: 0.9960     \n",
      "Epoch 35/70\n",
      "1000/1000 [==============================] - 5s - loss: 0.0150 - acc: 0.9980     \n",
      "Epoch 36/70\n",
      "1000/1000 [==============================] - 5s - loss: 0.0207 - acc: 0.9940     \n",
      "Epoch 37/70\n",
      "1000/1000 [==============================] - 5s - loss: 0.0090 - acc: 0.9990     \n",
      "Epoch 38/70\n",
      "1000/1000 [==============================] - 5s - loss: 0.0149 - acc: 0.9960     \n",
      "Epoch 39/70\n",
      "1000/1000 [==============================] - 5s - loss: 0.0088 - acc: 0.9980     \n",
      "Epoch 40/70\n",
      "1000/1000 [==============================] - 5s - loss: 0.0082 - acc: 0.9990     \n",
      "Epoch 41/70\n",
      "1000/1000 [==============================] - 5s - loss: 0.0184 - acc: 0.9960     \n",
      "Epoch 42/70\n",
      "1000/1000 [==============================] - 6s - loss: 0.0074 - acc: 0.9980     \n",
      "Epoch 43/70\n",
      "1000/1000 [==============================] - 5s - loss: 0.0179 - acc: 0.9950     \n",
      "Epoch 44/70\n",
      "1000/1000 [==============================] - 5s - loss: 0.0153 - acc: 0.9970     \n",
      "Epoch 45/70\n",
      "1000/1000 [==============================] - 5s - loss: 0.0124 - acc: 0.9980     \n",
      "Epoch 46/70\n",
      "1000/1000 [==============================] - 6s - loss: 0.0094 - acc: 0.9980     \n",
      "Epoch 47/70\n",
      "1000/1000 [==============================] - 6s - loss: 0.0133 - acc: 0.9960     \n",
      "Epoch 48/70\n",
      "1000/1000 [==============================] - 6s - loss: 0.0098 - acc: 0.9980     \n",
      "Epoch 49/70\n",
      "1000/1000 [==============================] - 5s - loss: 0.0058 - acc: 1.0000     \n",
      "Epoch 50/70\n",
      "1000/1000 [==============================] - 5s - loss: 0.0095 - acc: 0.9980     \n",
      "Epoch 51/70\n",
      "1000/1000 [==============================] - 5s - loss: 0.0188 - acc: 0.9970     \n",
      "Epoch 52/70\n",
      "1000/1000 [==============================] - 5s - loss: 0.0120 - acc: 0.9980     \n",
      "Epoch 53/70\n",
      "1000/1000 [==============================] - 5s - loss: 0.0094 - acc: 0.9980     \n",
      "Epoch 54/70\n",
      "1000/1000 [==============================] - 5s - loss: 0.0093 - acc: 0.9990     \n",
      "Epoch 55/70\n",
      "1000/1000 [==============================] - 5s - loss: 0.0077 - acc: 0.9990     \n",
      "Epoch 56/70\n",
      "1000/1000 [==============================] - 5s - loss: 0.0133 - acc: 0.9980     \n",
      "Epoch 57/70\n",
      "1000/1000 [==============================] - 5s - loss: 0.0057 - acc: 0.9990     \n",
      "Epoch 58/70\n",
      "1000/1000 [==============================] - 5s - loss: 0.0082 - acc: 0.9980     \n",
      "Epoch 59/70\n",
      "1000/1000 [==============================] - 5s - loss: 0.0097 - acc: 0.9970     \n",
      "Epoch 60/70\n",
      "1000/1000 [==============================] - 5s - loss: 0.0054 - acc: 0.9990     \n",
      "Epoch 61/70\n",
      "1000/1000 [==============================] - 5s - loss: 0.0110 - acc: 0.9990     \n",
      "Epoch 62/70\n",
      "1000/1000 [==============================] - 5s - loss: 0.0074 - acc: 0.9990     \n",
      "Epoch 63/70\n",
      "1000/1000 [==============================] - 5s - loss: 0.0058 - acc: 0.9980     \n",
      "Epoch 64/70\n",
      "1000/1000 [==============================] - 5s - loss: 0.0114 - acc: 0.9980     \n",
      "Epoch 65/70\n",
      "1000/1000 [==============================] - 5s - loss: 0.0043 - acc: 0.9990     \n",
      "Epoch 66/70\n",
      "1000/1000 [==============================] - 5s - loss: 0.0068 - acc: 0.9990     \n",
      "Epoch 67/70\n",
      "1000/1000 [==============================] - 5s - loss: 0.0041 - acc: 1.0000     \n",
      "Epoch 68/70\n",
      "1000/1000 [==============================] - 5s - loss: 0.0070 - acc: 0.9970     \n",
      "Epoch 69/70\n",
      "1000/1000 [==============================] - 5s - loss: 0.0104 - acc: 0.9980     \n",
      "Epoch 70/70\n",
      "1000/1000 [==============================] - 5s - loss: 0.0057 - acc: 0.9980     \n"
     ]
    }
   ],
   "source": [
    "historySR = networkSR.fit(\n",
    "            imagesTr, SRlabelsTr,\n",
    "            batch_size=50, epochs=70, shuffle=False) \n",
    "\n",
    "historySD = networkSD.fit(\n",
    "            imagesTr, SDlabelsTr,\n",
    "            batch_size=50, epochs=70, shuffle=False) \n",
    "\n",
    "historySiam = siamNetSD.fit(\n",
    "            [imagesTrNewR, imagesTrNewL], [SDlabelsTrSiam],\n",
    "            batch_size=50, epochs=70, shuffle=False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "networkSR.save(\"networkSR.h5\")\n",
    "networkSD.save(\"siamNetSD.h5\")\n",
    "siamNetSD.save(\"siamNetSD.h5\")\n",
    "\n",
    "# networkSR = load_model('networkSR.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "0.999\n"
     ]
    }
   ],
   "source": [
    "perfSR=[]\n",
    "perfSD=[]\n",
    "predSD = networkSD.predict(imagesTe)\n",
    "predSD=np.around(predSD)\n",
    "resTeSD=np.subtract(SDlabelsTe.flatten(),predSD.flatten())\n",
    "perfSD.append(1-sum(abs(resTeSD))/len(resTeSD))\n",
    "\n",
    "predSR = networkSR.predict(imagesTe)\n",
    "predSR=np.around(predSR)\n",
    "resTeSR=np.subtract(SRlabelsTe.flatten(),predSR.flatten())\n",
    "perfSR.append(1-sum(abs(resTeSR))/len(resTeSR))\n",
    "\n",
    "print(np.mean(perfSD))\n",
    "print(np.mean(perfSR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.955\n"
     ]
    }
   ],
   "source": [
    "perfSDsia=[]\n",
    "predSDsia = siamNetSD.predict([imagesTeNewR,imagesTeNewL])\n",
    "predSDsia=np.around(predSDsia)\n",
    "resTeSDsia=np.subtract(SDlabelsTeSiam.flatten(),predSDsia.flatten())\n",
    "perfSDsia.append(1-sum(abs(resTeSDsia))/len(resTeSDsia))\n",
    "print(np.mean(perfSDsia))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we save all the results for further analysis in Matlab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sio.savemat('perfSR01.mat', mdict={'perfSR':perfSR})\n",
    "sio.savemat('perfSD01.mat', mdict={'perfSD':perfSD})\n",
    "\n",
    "historyAccSR=historySR.history['acc']\n",
    "historyAccSD=historySD.history['acc']\n",
    "\n",
    "sio.savemat('historyAccSR01.mat', mdict={'historyAccSR':historyAccSR})\n",
    "sio.savemat('historyAccSD01.mat', mdict={'historyAccSD':historyAccSD})\n",
    "\n",
    "\n",
    "sio.savemat('perfSD10sia.mat', mdict={'perfSDsia':perfSDsia})\n",
    "\n",
    "historyAccSDsia=historySiam.history['acc']\n",
    "\n",
    "sio.savemat('historyAccSDsia10.mat', mdict={'historyAccSDsia':historyAccSDsia})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
